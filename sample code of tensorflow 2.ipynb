{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 1.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\tf2_gpu\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "in_a = tf.placeholder(dtype=tf.float32, shape=(2))\n",
    "def model(x):\n",
    "    with tf.variable_scope(\"matmul\"):\n",
    "        W = tf.get_variable(\"W\", initializer=tf.ones(shape=(2,2)))\n",
    "        b = tf.get_variable(\"b\", initializer=tf.zeros(shape=(2)))\n",
    "    return x * W + b\n",
    "out_a = model(in_a)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outs = sess.run([out_a],\n",
    "                feed_dict={in_a: [1, 0]})\n",
    "    writer = tf.summary.FileWriter(\"./logs/example\", sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 1.3835 - acc: 0.6578 - val_loss: 0.8977 - val_acc: 0.8243\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.7955 - acc: 0.8262 - val_loss: 0.6589 - val_acc: 0.8574\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 4s 74us/sample - loss: 0.6447 - acc: 0.8491 - val_loss: 0.5630 - val_acc: 0.8690\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.5718 - acc: 0.8607 - val_loss: 0.5096 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.5274 - acc: 0.8684 - val_loss: 0.4751 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.4969 - acc: 0.8737 - val_loss: 0.4507 - val_acc: 0.8877\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.4744 - acc: 0.8776 - val_loss: 0.4326 - val_acc: 0.8913\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.4569 - acc: 0.8809 - val_loss: 0.4182 - val_acc: 0.8941\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.4428 - acc: 0.8837 - val_loss: 0.4066 - val_acc: 0.8957\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.4312 - acc: 0.8863 - val_loss: 0.3969 - val_acc: 0.8974\n",
      "10000/10000 [==============================] - 3s 260us/sample - loss: 0.3988 - acc: 0.8952\n",
      "Test accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "# Network and training parameters.\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# Loading MNIST dataset.\n",
    "# verify\n",
    "# You can verify that the split between train and test is 60,000, and 10,000 respectively.\n",
    "# Labels have one-hot representation.is automatically applied\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# X_train is 60000 rows of 28x28 values; we --> reshape it to\n",
    "# 60000 x 784.\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Normalize inputs to be within in [0, 1].\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# One-hot representation of the labels.\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "\n",
    "# Build the model.\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(NB_CLASSES,\n",
    "input_shape=(RESHAPED,),\n",
    "name='dense_layer',\n",
    "activation='softmax'))\n",
    "\n",
    "# Compiling the model.\n",
    "model.compile(optimizer='SGD',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "# Training the model.\n",
    "model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "#evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.feature_column as fc\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "features = ['CRIM', 'ZN',\n",
    "'INDUS','CHAS','NOX','RM','AGE',\n",
    "'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "x_train_df = pd.DataFrame(x_train, columns= features)\n",
    "x_test_df = pd.DataFrame(x_test, columns= features)\n",
    "y_train_df = pd.DataFrame(y_train, columns=['MEDV'])\n",
    "y_test_df = pd.DataFrame(y_test, columns=['MEDV'])\n",
    "x_train_df.head()\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in features:\n",
    "    feature_columns.append(fc.numeric_column(feature_name,\n",
    "    dtype=tf.float32))\n",
    "\n",
    "def estimator_input_fn(df_data, df_label, epochs=10, shuffle=True,batch_size=32):\n",
    "    def input_function():\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df_data), df_label))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(100)\n",
    "        ds = ds.batch(batch_size).repeat(epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = estimator_input_fn(x_train_df, y_train_df)\n",
    "val_input_fn = estimator_input_fn(x_test_df, y_test_df, epochs=1,shuffle=False)\n",
    "\n",
    "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_\n",
    "columns)\n",
    "linear_est.train(train_input_fn, steps=100)\n",
    "result = linear_est.evaluate(val_input_fn)\n",
    "\n",
    "result = linear_est.predict(val_input_fn)\n",
    "for pred,exp in zip(result, y_test[:32]):\n",
    "print(\"Predicted Value: \", pred['predictions'][0], \"Expected:\n",
    "\", exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist_model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000214E2B583C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist_model/model.ckpt-60\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 60 into mnist_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.54413337, step = 60\n",
      "INFO:tensorflow:Saving checkpoints for 160 into mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.48367187.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-11-23T21:54:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist_model/model.ckpt-160\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-11-23-21:54:41\n",
      "INFO:tensorflow:Saving dict for global step 160: accuracy = 0.8998, average_loss = 0.3639235, global_step = 160, loss = 0.36235926\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 160: mnist_model/model.ckpt-160\n",
      "{'accuracy': 0.8998, 'average_loss': 0.3639235, 'loss': 0.36235926, 'global_step': 160}\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "\n",
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    "(eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\",shape=[28, 28])]\n",
    "\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "feature_columns=feature_columns,\n",
    "n_classes=10,\n",
    "model_dir=\"mnist_model/\"\n",
    ")\n",
    "\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "x={\"x\": train_data},\n",
    "y=train_labels,\n",
    "batch_size=100,\n",
    "num_epochs=None,\n",
    "shuffle=True)\n",
    "\n",
    "classifier.train(input_fn=train_input_fn, steps=100)\n",
    "\n",
    "val_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "x={\"x\": eval_data},\n",
    "y=eval_labels,\n",
    "num_epochs=1,\n",
    "shuffle=False)\n",
    "\n",
    "eval_results = classifier.evaluate(input_fn=val_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
